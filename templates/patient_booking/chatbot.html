<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>AI Medical Appointment Chatbot</title>

  <!-- ===== üé® STYLES ===== -->
  <style>
    /* ====== RESET & BASE ====== */
/* ====== RESET & BASE ====== */
* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

html, body {
  height: 100%;
  font-family: "Inter", "Segoe UI", Tahoma, Geneva, Verdana, sans-serif;
  background-color: #f9fafb;
  color: #111;
  display: flex;
  flex-direction: column;
}

/* ====== CHAT WRAPPER ====== */
.chat-wrapper {
  display: flex;
  flex-direction: column;
  height: 100%;
  width: 100%;
  max-width: 900px;
  margin: auto;
  background: #ffffff;
  border: 1px solid #e5e7eb;
  border-radius: 20px;
  box-shadow: 0 4px 30px rgba(0, 0, 0, 0.05);
  overflow: hidden;
}

/* ====== HEADER ====== */
.chat-header {
  background: #ffffff;
  border-bottom: 1px solid #e5e7eb;
  color: #111;
  padding: 18px 30px;
  display: flex;
  justify-content: space-between;
  align-items: center;
}

.chat-header h1 {
  font-size: 18px;
  font-weight: 600;
  display: flex;
  align-items: center;
  gap: 8px;
}

.chat-header p {
  font-size: 14px;
  color: #6b7280;
}

/* ====== MAIN CHAT AREA ====== */
.messages {
  flex: 1;
  overflow-y: auto;
  padding: 30px 40px;
  background: #fafafa;
  display: flex;
  flex-direction: column;
  scroll-behavior: smooth;
}

.message {
  display: flex;
  margin-bottom: 20px;
  animation: fadeIn 0.4s ease forwards;
}

@keyframes fadeIn {
  from {
    opacity: 0;
    transform: translateY(5px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

.message-content {
  max-width: 70%;
  padding: 14px 18px;
  border-radius: 16px;
  font-size: 15px;
  line-height: 1.6;
  word-wrap: break-word;
}

.bot-message {
  justify-content: flex-start;
}

.bot-message .message-content {
  background: #f3f4f6;
  color: #111;
  border-top-left-radius: 6px;
}

.user-message {
  justify-content: flex-end;
}

.user-message .message-content {
  background: #2563eb;
  color: white;
  border-top-right-radius: 6px;
}

/* ====== TYPING INDICATOR ====== */
.typing-indicator {
  display: none;
  align-self: flex-start;
  background: #f3f4f6;
  padding: 10px 16px;
  border-radius: 15px;
  margin-left: 10px;
  box-shadow: 0 1px 3px rgba(0, 0, 0, 0.1);
}

.typing-indicator span {
  height: 8px;
  width: 8px;
  background: #2563eb;
  display: inline-block;
  border-radius: 50%;
  margin-right: 4px;
  animation: typing 1.4s infinite;
}

.typing-indicator span:nth-child(2) { animation-delay: 0.2s; }
.typing-indicator span:nth-child(3) { animation-delay: 0.4s; }

@keyframes typing {
  0%, 60%, 100% { transform: translateY(0); }
  30% { transform: translateY(-6px); }
}

/* ====== OPTIONS ====== */
.options-container {
  display: flex;
  flex-wrap: wrap;
  gap: 10px;
  padding: 0 40px 15px 40px;
}

.option-btn {
  padding: 8px 18px;
  border-radius: 20px;
  border: 1.8px solid #2563eb;
  background: #ffffff;
  color: #2563eb;
  font-size: 14px;
  cursor: pointer;
  transition: all 0.3s ease;
}

.option-btn:hover {
  background: #2563eb;
  color: white;
  transform: translateY(-2px);
}

/* Available slot styling - light green border */
.option-btn.available {
  border: 2px solid #10b981;
  background: #f0fdf4;
  color: #059669;
}

.option-btn.available:hover {
  background: #10b981;
  color: white;
  transform: translateY(-2px);
  box-shadow: 0 4px 12px rgba(16, 185, 129, 0.3);
}

/* Booked/unavailable slot styling - light red border */
.option-btn.booked {
  border: 2px solid #ef4444;
  background: #fef2f2;
  color: #dc2626;
  cursor: not-allowed;
  opacity: 0.7;
}

.option-btn.booked:hover {
  background: #fef2f2;
  color: #dc2626;
  transform: none;
}

.skip-btn {
  background: #f3f4f6;
  border-color: #d1d5db;
  color: #6b7280;
}

.skip-btn:hover {
  background: #e5e7eb;
}

/* ====== INPUT AREA ====== */
.input-area {
  display: flex;
  align-items: center;
  padding: 18px 30px;
  background: #ffffff;
  border-top: 1px solid #e5e7eb;
  gap: 10px;
}

#user-input {
  flex: 1;
  padding: 12px 20px;
  border: 1.5px solid #d1d5db;
  border-radius: 25px;
  background: #f9fafb;
  color: #111;
  font-size: 15px;
  outline: none;
  transition: all 0.3s ease;
}

#user-input::placeholder {
  color: #9ca3af;
}

#user-input:focus {
  border-color: #2563eb;
  background: #ffffff;
}

.voice-btn {
  padding: 12px;
  width: 45px;
  height: 45px;
  border-radius: 50%;
  border: none;
  cursor: pointer;
  font-size: 18px;
  transition: all 0.25s ease;
  display: flex;
  align-items: center;
  justify-content: center;
}

#mic-btn {
  background: #10b981;
  color: white;
}

#mic-btn:hover {
  background: #059669;
  transform: scale(1.05);
}

#mic-btn.recording {
  background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
  animation: pulse 1.5s infinite;
  box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7);
}

#speaker-btn {
  background: #6366f1;
  color: white;
}

#speaker-btn:hover {
  background: #4f46e5;
  transform: scale(1.05);
}

#speaker-btn.disabled {
  background: #9ca3af;
  cursor: not-allowed;
}

#send-btn {
  padding: 12px 22px;
  border-radius: 25px;
  background: #2563eb;
  color: white;
  border: none;
  cursor: pointer;
  font-size: 15px;
  font-weight: 500;
  transition: all 0.25s ease;
}

#send-btn:hover {
  background: #1e40af;
  transform: scale(1.05);
}

@keyframes pulse {
  0%, 100% {
    box-shadow: 0 0 0 0 rgba(239, 68, 68, 0.7);
  }
  50% {
    box-shadow: 0 0 0 10px rgba(239, 68, 68, 0);
  }
}

/* Voice status indicator */
.voice-status {
  display: none;
  padding: 10px 18px;
  background: linear-gradient(135deg, #f3f4f6 0%, #e5e7eb 100%);
  border-radius: 20px;
  font-size: 14px;
  color: #374151;
  align-items: center;
  gap: 10px;
  box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);
  font-weight: 500;
  margin: 0 30px 10px 30px;
  border: 2px solid transparent;
  transition: all 0.3s ease;
}

.voice-status.active {
  display: flex;
  border-color: #10b981;
  background: linear-gradient(135deg, #dcfce7 0%, #bbf7d0 100%);
  color: #065f46;
}

.voice-status .status-dot {
  width: 10px;
  height: 10px;
  border-radius: 50%;
  background: #10b981;
  animation: blink 1s infinite;
  box-shadow: 0 0 8px rgba(16, 185, 129, 0.5);
}

@keyframes blink {
  0%, 100% { opacity: 1; transform: scale(1); }
  50% { opacity: 0.5; transform: scale(0.9); }
}

/* ====== SCROLLBAR ====== */
.messages::-webkit-scrollbar {
  width: 6px;
}

.messages::-webkit-scrollbar-thumb {
  background: #d1d5db;
  border-radius: 4px;
}

.messages::-webkit-scrollbar-thumb:hover {
  background: #9ca3af;
}

@media (max-width: 768px) {
  .chat-wrapper {
    border-radius: 0;
  }
  .messages {
    padding: 20px;
  }
  .input-area {
    padding: 15px 20px;
  }
}
  </style>
</head>

<body>
  <!-- ===== üí¨ CHAT INTERFACE ===== -->
  <div class="chat-wrapper">
    <div class="chat-header">
      <h1><span>üè•</span> AI Medical Assistant</h1>
      <p>Helping you book appointments smarter</p>
    </div>

    <div class="messages" id="messages">
      <div class="message bot-message">
        <div class="message-content">
          Hello! üëã I‚Äôm your AI appointment assistant.<br><br>
          How can I assist you today?
        </div>
      </div>
    </div>

    <div class="typing-indicator" id="typing-indicator">
      <span></span><span></span><span></span>
    </div>

    <div class="options-container" id="options-container"></div>

    <div class="voice-status" id="voice-status">
      <span class="status-dot"></span>
      <span id="voice-status-text">Listening...</span>
    </div>

    <div class="input-area">
      <button class="voice-btn" id="mic-btn" title="Voice Input">üé§</button>
      <input type="text" id="user-input" placeholder="Type or click üé§ for voice conversation..." autocomplete="off" />
      <button class="voice-btn" id="speaker-btn" title="Voice Output">üîä</button>
      <button id="send-btn">Send</button>
    </div>
  </div>

  <!-- ===== ‚öôÔ∏è SCRIPT ===== -->
  <script>
    let sessionId = generateSessionId();
    let voiceEnabled = false;
    let isRecording = false;
    let conversationMode = false;  // NEW: Conversational AI mode
    let recognition = null;
    let synthesis = window.speechSynthesis;
    let silenceTimer = null;  // NEW: Timer to detect end of speech
    let interimTranscript = '';  // NEW: Track interim results
    let finalTranscript = '';  // NEW: Track final transcript

    // ===== INTELLIGENT VAD SYSTEM =====
    let audioContext = null;
    let microphone = null;
    let analyser = null;
    let vadEnabled = false;
    let speechDetected = false;
    let lastSpeechTime = 0;
    let speechStartTime = 0;
    let energyHistory = [];
    let idleTimeout = null;
    const ENERGY_THRESHOLD = 0.015;  // Threshold for speech detection
    const SILENCE_THRESHOLD = 0.008;  // Lower threshold for silence
    const MIN_SPEECH_DURATION = 200;  // Minimum speech duration (ms)
    const IDLE_TIMEOUT = 30000;  // Go idle after 30 seconds of no activity

    // Initialize Web Speech API
    if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
      recognition = new SpeechRecognition();
      recognition.continuous = true;  // CHANGED: Enable continuous listening
      recognition.interimResults = true;  // CHANGED: Enable interim results for better VAD
      recognition.lang = 'en-IN'; // English (India)

      recognition.onstart = function() {
        isRecording = true;
        document.getElementById('mic-btn').classList.add('recording');
        document.getElementById('voice-status').classList.add('active');

        if (conversationMode) {
          document.getElementById('voice-status-text').textContent = 'üéôÔ∏è I\'m listening... speak naturally';
        } else {
          document.getElementById('voice-status-text').textContent = 'Listening...';
        }
      };

      recognition.onresult = function(event) {
        // NEW: Handle both interim and final results
        interimTranscript = '';
        finalTranscript = '';

        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          if (event.results[i].isFinal) {
            finalTranscript += transcript + ' ';
          } else {
            interimTranscript += transcript;
          }
        }

        // Update input field with current speech
        const currentText = (finalTranscript + interimTranscript).trim();
        if (currentText) {
          // Wake from idle if needed
          if (conversationMode && document.getElementById('voice-status').style.opacity !== '1') {
            wakeFromIdle();
          }

          document.getElementById('user-input').value = currentText;

          if (conversationMode) {
            document.getElementById('voice-status-text').textContent = 'üé§ ' + currentText.substring(0, 30) + '...';
          }
        }

        // IMPROVED: Intelligent Voice Activity Detection with adaptive timeout
        if (conversationMode && finalTranscript) {
          // Clear existing timer
          if (silenceTimer) {
            clearTimeout(silenceTimer);
          }

          // Reset idle timeout
          resetIdleTimeout();

          // Calculate dynamic timeout based on speech patterns
          const dynamicTimeout = calculateDynamicTimeout(finalTranscript);

          // Set adaptive timer - faster response for short utterances
          silenceTimer = setTimeout(() => {
            if (finalTranscript.trim()) {
              document.getElementById('voice-status-text').textContent = '‚ú® Processing...';
              autoSendMessage();
            }
          }, dynamicTimeout);
        } else if (!conversationMode) {
          // OLD BEHAVIOR: Auto-send if confidence is high (non-conversation mode)
          const confidence = event.results[0][0].confidence;
          if (confidence > 0.7) {
            setTimeout(() => sendMessage(), 500);
          }
        }
      };

      recognition.onerror = function(event) {
        console.error('Speech recognition error:', event.error);

        // Don't stop conversation mode for no-speech errors
        if (event.error === 'no-speech' && conversationMode) {
          // Just continue listening
          return;
        }

        if (!conversationMode) {
          stopRecording();
        }

        if (event.error === 'no-speech') {
          if (!conversationMode) {
            showVoiceStatus('No speech detected. Please try again.', 'error');
          }
        } else if (event.error === 'not-allowed') {
          showVoiceStatus('Microphone access denied. Please enable it.', 'error');
          stopConversationMode();
        } else if (event.error !== 'aborted') {
          showVoiceStatus('Voice recognition error. Please try typing.', 'error');
        }
      };

      recognition.onend = function() {
        // NEW: Auto-restart if in conversation mode
        if (conversationMode && isRecording) {
          try {
            recognition.start();
          } catch (e) {
            console.log('Recognition restart skipped:', e);
          }
        } else {
          stopRecording();
        }
      };
    }

    // ===== INTELLIGENT VAD FUNCTIONS =====

    async function initializeAudioAnalysis() {
      // Initialize Web Audio API for energy-based VAD
      try {
        audioContext = new (window.AudioContext || window.webkitAudioContext)();
        analyser = audioContext.createAnalyser();
        analyser.fftSize = 256;
        analyser.smoothingTimeConstant = 0.8;

        const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        microphone = audioContext.createMediaStreamSource(stream);
        microphone.connect(analyser);

        vadEnabled = true;
        monitorVoiceActivity();

        console.log('‚úÖ Intelligent VAD initialized');
      } catch (error) {
        console.warn('Audio analysis not available:', error);
        vadEnabled = false;
      }
    }

    function calculateAudioEnergy() {
      // Calculate current audio energy level
      if (!analyser) return 0;

      const dataArray = new Uint8Array(analyser.frequencyBinCount);
      analyser.getByteFrequencyData(dataArray);

      // Calculate RMS (Root Mean Square) energy
      let sum = 0;
      for (let i = 0; i < dataArray.length; i++) {
        sum += (dataArray[i] / 255) * (dataArray[i] / 255);
      }
      const rms = Math.sqrt(sum / dataArray.length);

      // Keep history for adaptive thresholding
      energyHistory.push(rms);
      if (energyHistory.length > 50) energyHistory.shift();

      return rms;
    }

    function monitorVoiceActivity() {
      // Continuous monitoring of voice activity
      if (!vadEnabled || !conversationMode) return;

      const energy = calculateAudioEnergy();
      const now = Date.now();

      // Detect speech start
      if (energy > ENERGY_THRESHOLD && !speechDetected) {
        speechDetected = true;
        speechStartTime = now;
        lastSpeechTime = now;
      }

      // Update last speech time if still speaking
      if (energy > SILENCE_THRESHOLD && speechDetected) {
        lastSpeechTime = now;
      }

      // Detect speech end (intelligent detection)
      if (speechDetected && energy < SILENCE_THRESHOLD) {
        const silenceDuration = now - lastSpeechTime;
        const speechDuration = lastSpeechTime - speechStartTime;

        // Only trigger if we had meaningful speech
        if (silenceDuration > 400 && speechDuration > MIN_SPEECH_DURATION) {
          speechDetected = false;
          // The recognition.onresult will handle the actual sending
        }
      }

      // Continue monitoring
      if (conversationMode) {
        requestAnimationFrame(monitorVoiceActivity);
      }
    }

    function calculateDynamicTimeout(transcript) {
      // INTELLIGENT: Calculate adaptive timeout based on speech patterns
      const wordCount = transcript.trim().split(/\s+/).length;
      const charCount = transcript.trim().length;

      // Short responses (1-3 words) - faster timeout
      if (wordCount <= 3) {
        return 500;  // 0.5 seconds - MUCH faster than 1.5s!
      }

      // Medium responses (4-8 words) - moderate timeout
      if (wordCount <= 8) {
        return 700;  // 0.7 seconds
      }

      // Longer responses - slightly longer timeout (but still faster)
      if (wordCount <= 15) {
        return 900;  // 0.9 seconds
      }

      // Very long responses - standard timeout
      return 1200;  // 1.2 seconds (still faster than 1.5s)
    }

    function resetIdleTimeout() {
      // Reset the idle timer
      if (idleTimeout) {
        clearTimeout(idleTimeout);
      }

      // Set new idle timer
      if (conversationMode) {
        idleTimeout = setTimeout(() => {
          enterIdleMode();
        }, IDLE_TIMEOUT);
      }
    }

    function enterIdleMode() {
      // Enter sleep/idle mode after inactivity
      if (!conversationMode) return;

      document.getElementById('voice-status-text').textContent = 'üò¥ Idle mode - say something to wake me...';

      // Visual indicator for idle
      const statusEl = document.getElementById('voice-status');
      statusEl.style.opacity = '0.6';

      // Clear any pending timers
      if (silenceTimer) {
        clearTimeout(silenceTimer);
        silenceTimer = null;
      }

      // Reset state
      finalTranscript = '';
      interimTranscript = '';
      speechDetected = false;
    }

    function wakeFromIdle() {
      // Wake from idle mode when speech detected
      const statusEl = document.getElementById('voice-status');
      statusEl.style.opacity = '1';
      document.getElementById('voice-status-text').textContent = 'üéôÔ∏è I\'m listening...';
      resetIdleTimeout();
    }

    function generateSessionId() {
      return "session_" + Date.now() + "_" + Math.random().toString(36).substr(2, 9);
    }

    function toggleVoiceInput() {
      if (!recognition) {
        alert('Voice recognition is not supported in your browser. Please use Chrome or Edge.');
        return;
      }

      if (isRecording || conversationMode) {
        // Stop conversation mode
        stopConversationMode();
      } else {
        // Start conversation mode
        startConversationMode();
      }
    }

    async function startConversationMode() {
      conversationMode = true;
      finalTranscript = '';
      interimTranscript = '';

      // Initialize intelligent VAD
      if (!vadEnabled && !audioContext) {
        await initializeAudioAnalysis();
      }

      // Auto-enable voice output for conversational experience
      if (!voiceEnabled) {
        voiceEnabled = true;
        const speakerBtn = document.getElementById('speaker-btn');
        speakerBtn.textContent = 'üîä';
        speakerBtn.classList.remove('disabled');
      }

      try {
        recognition.start();
        document.getElementById('mic-btn').classList.add('recording');
        document.getElementById('mic-btn').title = 'Stop Conversation';

        // Start idle timeout
        resetIdleTimeout();

        // Start VAD monitoring
        if (vadEnabled) {
          monitorVoiceActivity();
          showVoiceStatus('üéôÔ∏è Intelligent voice mode active!', 'success');
        } else {
          showVoiceStatus('üéôÔ∏è Conversation mode active - speak naturally!', 'success');
        }

        setTimeout(() => {
          if (conversationMode) {
            document.getElementById('voice-status-text').textContent = 'üéôÔ∏è I\'m listening...';
            // Reset opacity if coming from idle
            document.getElementById('voice-status').style.opacity = '1';
          }
        }, 2000);
      } catch (error) {
        console.error('Error starting conversation mode:', error);
        conversationMode = false;
      }
    }

    function stopConversationMode() {
      conversationMode = false;
      isRecording = false;
      vadEnabled = false;

      // Clear all timers
      if (silenceTimer) {
        clearTimeout(silenceTimer);
        silenceTimer = null;
      }

      if (idleTimeout) {
        clearTimeout(idleTimeout);
        idleTimeout = null;
      }

      try {
        recognition.stop();
      } catch (error) {
        console.log('Recognition already stopped');
      }

      // Clean up audio context
      if (microphone) {
        microphone.disconnect();
        microphone = null;
      }

      if (audioContext && audioContext.state !== 'closed') {
        audioContext.close();
        audioContext = null;
      }

      document.getElementById('mic-btn').classList.remove('recording');
      document.getElementById('mic-btn').title = 'Voice Input';
      document.getElementById('voice-status').classList.remove('active');
      document.getElementById('voice-status').style.opacity = '1';

      finalTranscript = '';
      interimTranscript = '';
      speechDetected = false;
      energyHistory = [];
    }

    function stopRecording() {
      if (!conversationMode) {
        isRecording = false;
        document.getElementById('mic-btn').classList.remove('recording');
        document.getElementById('voice-status').classList.remove('active');
      }
    }

    function autoSendMessage() {
      // NEW: Automatically send message in conversation mode
      const input = document.getElementById('user-input');
      const message = input.value.trim();

      if (!message) return;

      // Clear the timer
      if (silenceTimer) {
        clearTimeout(silenceTimer);
        silenceTimer = null;
      }

      // Reset transcripts
      finalTranscript = '';
      interimTranscript = '';

      // Pause listening while processing
      document.getElementById('voice-status-text').textContent = 'ü§ñ Bot is thinking...';

      // Send the message
      sendMessage().then(() => {
        // Resume listening after bot responds (happens in speak function)
      });
    }

    function toggleVoiceOutput() {
      voiceEnabled = !voiceEnabled;
      const speakerBtn = document.getElementById('speaker-btn');

      if (voiceEnabled) {
        speakerBtn.textContent = 'üîä';
        speakerBtn.classList.remove('disabled');
        showVoiceStatus('Voice output enabled', 'success');
      } else {
        speakerBtn.textContent = 'üîá';
        speakerBtn.classList.add('disabled');
        synthesis.cancel(); // Stop any ongoing speech
        showVoiceStatus('Voice output disabled', 'info');
      }

      // Hide status after 2 seconds
      setTimeout(() => {
        if (!isRecording) {
          document.getElementById('voice-status').classList.remove('active');
        }
      }, 2000);
    }

    function showVoiceStatus(message, type = 'info') {
      const statusEl = document.getElementById('voice-status');
      const statusText = document.getElementById('voice-status-text');

      statusText.textContent = message;
      statusEl.classList.add('active');

      // Auto-hide after 3 seconds
      setTimeout(() => {
        if (!isRecording) {
          statusEl.classList.remove('active');
        }
      }, 3000);
    }

    function speak(text) {
      if (!voiceEnabled || !synthesis) {
        // If conversation mode but voice disabled, still resume listening
        if (conversationMode) {
          resumeListeningAfterResponse();
        }
        return;
      }

      // Cancel any ongoing speech
      synthesis.cancel();

      // Remove HTML tags
      const cleanText = text.replace(/<[^>]+>/g, '').replace(/\n/g, '. ');

      const utterance = new SpeechSynthesisUtterance(cleanText);
      utterance.lang = 'en-IN';
      utterance.rate = 0.9; // Slightly slower for clarity
      utterance.pitch = 1.0;
      utterance.volume = 1.0;

      // Get Indian English voice if available
      const voices = synthesis.getVoices();
      const indianVoice = voices.find(voice =>
        voice.lang === 'en-IN' || voice.lang.startsWith('en-IN')
      );

      if (indianVoice) {
        utterance.voice = indianVoice;
      }

      utterance.onstart = function() {
        showVoiceStatus('üîä Speaking...', 'info');
      };

      utterance.onend = function() {
        // NEW: Resume listening after bot finishes speaking
        if (conversationMode) {
          resumeListeningAfterResponse();
        } else if (!isRecording) {
          document.getElementById('voice-status').classList.remove('active');
        }
      };

      synthesis.speak(utterance);
    }

    function resumeListeningAfterResponse() {
      // NEW: Resume listening in conversation mode after bot responds
      if (!conversationMode) return;

      setTimeout(() => {
        if (conversationMode) {
          finalTranscript = '';
          interimTranscript = '';
          document.getElementById('user-input').value = '';
          document.getElementById('voice-status-text').textContent = 'üéôÔ∏è I\'m listening...';
          document.getElementById('voice-status').classList.add('active');
        }
      }, 500);  // Small delay after speech ends
    }

    function addMessage(text, sender) {
      const messagesDiv = document.getElementById("messages");
      const messageDiv = document.createElement("div");
      messageDiv.className = `message ${sender}-message`;
      const contentDiv = document.createElement("div");
      contentDiv.className = "message-content";
      contentDiv.innerHTML = text.replace(/\n/g, "<br>");
      messageDiv.appendChild(contentDiv);
      messagesDiv.appendChild(messageDiv);
      messagesDiv.scrollTop = messagesDiv.scrollHeight;
    }

    function displayOptions(options) {
      const container = document.getElementById("options-container");
      container.innerHTML = "";
      if (!options || options.length === 0) {
        container.style.display = "none";
        return;
      }
      container.style.display = "flex";
      options.forEach((option) => {
        const btn = document.createElement("button");
        btn.className = "option-btn";

        // Handle skip buttons
        if (option.value === "skip" || option.label.includes("Skip")) {
          btn.classList.add("skip-btn");
        }

        // Handle availability styling for time/date slots
        if (option.hasOwnProperty('available')) {
          if (option.available === true) {
            // Available slot - green border
            btn.classList.add("available");
          } else if (option.available === false) {
            // Booked slot - red border and disabled
            btn.classList.add("booked");
            btn.disabled = true;
          }
        }
        // Fallback: check description field for availability markers
        else if (option.description) {
          if (option.description.includes('Available') || option.description.includes('‚úÖ')) {
            btn.classList.add("available");
          } else if (option.description.includes('Booked') || option.description.includes('‚ùå')) {
            btn.classList.add("booked");
            btn.disabled = true;
          }
        }

        // Set button text and include description if available
        if (option.description && !option.description.includes('years exp.')) {
          btn.textContent = `${option.label} ${option.description}`;
        } else {
          btn.textContent = option.label;
        }

        btn.onclick = () => {
          if (!btn.disabled) {
            selectOption(option.value, option.label);
          }
        };
        container.appendChild(btn);
      });
    }

    function selectOption(value, label) {
      document.getElementById("options-container").innerHTML = "";
      sendMessage(value, label);
    }

    function showTypingIndicator() {
      document.getElementById("typing-indicator").style.display = "flex";
      document.getElementById("messages").scrollTop = document.getElementById("messages").scrollHeight;
    }

    function hideTypingIndicator() {
      document.getElementById("typing-indicator").style.display = "none";
    }

    async function sendMessage(messageValue = null, displayText = null) {
      const input = document.getElementById("user-input");
      const message = messageValue || input.value.trim();
      const displayMessage = displayText || message;
      if (!message) return;

      addMessage(displayMessage, "user");
      if (!messageValue) input.value = "";

      // Clear input in conversation mode
      if (conversationMode) {
        input.value = "";
      }

      showTypingIndicator();

      try {
        const response = await fetch("/api/chatbot/", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ message, session_id: sessionId }),
        });
        const data = await response.json();
        hideTypingIndicator();

        if (data.success) {
          sessionId = data.session_id;
          addMessage(data.message, "bot");

          // Speak the response if voice is enabled
          if (voiceEnabled) {
            speak(data.message);
          } else if (conversationMode) {
            // Even without voice output, resume listening in conversation mode
            resumeListeningAfterResponse();
          }

          if (data.options) displayOptions(data.options);
          else document.getElementById("options-container").style.display = "none";
        } else {
          addMessage("‚ö†Ô∏è Sorry, something went wrong. Please try again.", "bot");
          if (conversationMode) {
            resumeListeningAfterResponse();
          }
        }
      } catch (err) {
        hideTypingIndicator();
        addMessage("üåê Network error. Please check your connection.", "bot");
        console.error(err);

        if (conversationMode) {
          resumeListeningAfterResponse();
        }
      }
    }

    // Event listeners
    document.getElementById("send-btn").addEventListener("click", () => sendMessage());
    document.getElementById("user-input").addEventListener("keypress", (e) => {
      if (e.key === "Enter") sendMessage();
    });

    document.getElementById("mic-btn").addEventListener("click", toggleVoiceInput);
    document.getElementById("speaker-btn").addEventListener("click", toggleVoiceOutput);

    // Load voices when they become available
    if (synthesis) {
      synthesis.onvoiceschanged = function() {
        const voices = synthesis.getVoices();
        console.log('Available voices:', voices.length);
      };
    }

    window.onload = () => {
      document.getElementById("user-input").focus();

      // Show voice feature hint
      setTimeout(() => {
        const voiceHint = "üí° <strong>Intelligent Voice Mode!</strong><br>Click üé§ to activate smart voice detection - I'll respond instantly when you finish speaking (no more waiting!). Speaks naturally and goes idle when quiet.";
        const hintDiv = document.createElement("div");
        hintDiv.className = "message bot-message";
        hintDiv.innerHTML = `<div class="message-content" style="background: #dbeafe; color: #1e40af; padding: 16px 20px;">${voiceHint}</div>`;
        document.getElementById("messages").appendChild(hintDiv);
      }, 1000);
    };
  </script>
</body>
</html>
